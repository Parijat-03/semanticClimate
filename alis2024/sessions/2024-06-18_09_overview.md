
## raw repository design

So I'll just talk to you. So this is the Peter MR semantic climate repository.


### alis2024
There's a Sub directory, oh called A list, 2024. And within that are the materials that we are going to reference in our presentation.

* The top level here contains a number of mark down files an HTML which is what people will read.

* There are figures here which I'll talk about in a minute. And there is a set of zoom recordings, of what we've done.

* So these are some of our Zoom recordings over the last few days running from the 3rd of June to the 14th of June.

Today is the 18.th so we will have another recording from that. So these recordings are put in there.

* 
Of, about 50 MB. You can just about get the audio up, but not the video.

#### open_notebook_

It's What we're aiming for is the idea of open notebook. Where everything we do is recorded and presented to the world.

What's holding us back at the moment? Is simply that it is technically very difficult to do this without friction.

#### friction
So let me introduce the concept of friction. Friction is where, You have to make a manual intervention to make something happen.

And it is a major problem in making a semantic universe. If you require a human to click something or a human to download something, or, Type something in.

It slows it down by, a thousand times. And that's been the problem of things like you the scientific literature and why pi get papers is such an important.

Development because it allows you to download things automatically. Scholarly literature has huge friction.

It's based on the idea that humans are required to make navigational decisions all the time. And Here, we.

# record everything

Overcome that by trying to automate how things are put out. To the web. So we record all these.

A typical one here. Has got, the audio, the video. And, the transcript And I have manually converted the transcript.

Into a markdown file here and that can be automatically created into a HTML transcript.

So the goal of this is to come up with some Yeah, I would. Semantically structured components here.

#### transcript
So if I bring up the transcript, it looks like, the following. So this is the raw transcript.

I'll make it bigger.

I'll make it, So.

What we've got is verbatim record. What? What I've done in my monologue, but, it's been transcribed and I've divided it up into sections.

It's Obviously not polished. But I think it's very readable. So in other words, what I'm saying at the moment, will actually not.

Look too bad on the printed page. Now, is, and more here.

And more.

#### interlude

<!--

So, what I've done here is I've taken the transcript from, about 4 or 5 days ago.

And simply gone through and added. Marked down separators here. I'll bring up the mark down as well.

So here's marked down for the same thing. I put that in by hand. It's not actually too difficult and it means I can make some changes.

As we go through but Assuming it's in HML, it should be possible to pull all of these.

Paragraphs out. And Is this a reasonable size to ask to be? summarized.

[Anmol Negi] 09:21:22
Okay.

Tell us about summarization.

[Renu Kumari] 09:21:30
So the summarization part was done by the. S. Yeah, so maybe Unmo has no idea about how.

Oh, I'm sorry. Oh, okay. Okay, forget that. My problem, okay.

[Renu Kumari] 09:21:40
Okay

Right. Well, if Harshal isn't with us, then, It's not gonna be very easy to, get that done before.

[Renu Kumari] 09:21:54
But he can do this because it's a very small length of the text.

Yes, and the question is can we automate it? In HTML it's very easy to pull these out.

Using x path okay. Can you contact him? Reno and see if he's able to, run his tools over this.

[Renu Kumari] 09:22:22
Okay.

Alright, okay. That's a bit of a, interruption. I'll cut that.

I'll cut all that out of the, transcript, when we're, putting it up.

For people. Okay, so, What we're talking about here then is the

Oh, hello, Harshal. Well.

Can you hear us?

[Renu Kumari] 09:23:03
For Hudson, there is also. You know, Is it? Okay, maybe the network is, I'll just mention.

Well, he's just joined.

[Anmol Negi] 09:23:20
You know.

We wait, she's on because this is very important and valuable.

While. Well, while we're doing that, all of you can check out.

HMR semantic climate and you'll be able to see this, right?

This needs actually a bit of. Editing. Because it's some of the.

Mark up in Mark, down hasn't. Mean.

What's the problem?

[Renu Kumari] 09:24:45
So, so it will begin from the article will begin from the here from the Ranganatan.

This will be, this will be part of it.

[Renu Kumari] 09:24:54
Okay.

Right. Remember, it doesn't begin anywhere. By the way, let me go through.

I should have a, an empty line between all of these so let me just

Do this was a regular expression phone. New line, hash. And replace it by.

2 new lines.

Oh

Sorry about all of that.

Yes. Are you with us Harshal?

[Renu Kumari] 09:27:04
Peter Hudson has joined.

[Renu Kumari] 09:27:08
Hmm.

[Harshul Surana] 09:27:11
Yes, good morning, beta.

Good morning, that's wonderful. Okay. What, I'd like your advice on is, We now have.

We have a number of components in this. Which have got sub components which we would like summarize.

So here is a typical. Example. this is on the web in,

Where's, it's called transcript.md. I made this manually.

Now the question is, can you, And, can you go through, something like this and can you summarize a sentence of that sort of size.

[Harshul Surana] 09:28:14
I didn't fully follow.

Right, we've now got paragraphs of this size. I'm creating these manually for some of these and I just wondered whether you can go through.

With the, summarize her and cut them down by, let's say, you know, reduce them to 60% or something like that.

Does that make sense?

-->

#### summarization

[Harshul Surana] 09:28:40
So you mean reducing the current summarized content to about 60% of it.

This is not summarized. This is raw. So, There's a lot of redundancy in this.

[Harshul Surana] 09:28:50
Great.

[Harshul Surana] 09:28:56
So you wanted summarized to 60%. Oh, Okay.

Something of that salt, yes. But, paragraph by paragraph.

[Harshul Surana] 09:29:06
Okay.

Does that make sense?

[Harshul Surana] 09:29:13
Yeah, I think I get it.

[Harshul Surana] 09:29:20
Okay.

So all this, we would call this, unless it's got special things and we would call this, you know, maybe 50 times or something like that.

To, summarize each of these paragraphs.

[Harshul Surana] 09:29:36
Right, so you want to use other paragraphs like. Divided by the headings separately.

Yes, I can do that if necessary. Using. And x path in HTML, right?

[Harshul Surana] 09:29:51
Hey. I can give it a try.

Sorry, I can give you the.

Do you what I'm trying to get up is do you think that this is about the sort of size which is, good for it.

[Harshul Surana] 09:30:10
It seems to be on the lower side, but I think it will work. It should work.

Right. I mean, we can put them together. We can, for example, this is a heavier header than this one here for example.

This is something like H 2 and these ones are 8 3 and this is 8 4 so we could actually.

Take the whole of that right.

[Harshul Surana] 09:30:38
Right.

It's, you know, it's not critical for production, but, you know, it's, you know, it would be very useful to be able to show it.

Does that make sense?

[Harshul Surana] 09:30:57
Alright, so you mean combining different paragraphs? Okay.

Well, You thought these paragraphs here were on the short side.

[Harshul Surana] 09:31:10
Right, but I think it should work.

Right, okay.

[Harshul Surana] 09:31:17
I'll give it a try.

That would be fantastic. Okay, so that is, available on the semantic climate repository the PTMR semantic climate repository.

[Harshul Surana] 09:31:38
Okay.

#### rejoin thread

And let me just get the.

Yeah. So what we've done, you see, so this is going back to everybody.

These ones I have recorded, this and, these are the This is the raw material that we got out the close captions.

Here I'll make that bigger.

So this is, close captions. And what I've done is I've gone through and I did mark down and also.

Cut out some of the things which, so I'm not, pairing these up at the moment.

But I've gone through and I've, taking the times out of this.

And, cut out some of the some of the management like what we're doing at the moment.

So this is the meaningful part of the raw transcript. So we'd like to summarize.

Paragraphs of this sort of thing.

[Harshul Surana] 09:33:03
And that's what I do take care.

I would have Be very interested in that. Okay. Right.

Okay. So let's go back and, get back onto our. Mainstream.

So.

So we've that's got a little bit interrupted so I'm actually going to start again and try and go through with a monologue.

And this will last about or, 40 min. And so yeah, I don't think we want, interruptions.

And, I'll take us through everything that needs to be in the high level table of contents.

So before we do that, are there any? Management questions, before we go in.

[Renu Kumari] 09:34:13
Peter, I'll be leaving at. Hmm. It's been 20 min because of some urban meeting.

And M, you were

That's fine. Absolutely. Right. Okay.

[Renu Kumari] 09:34:20
But others can continue. Yeah, but I'll join once I'll back.

So we don't need to stop the recording, but I will cut out all this stuff in the click transcript.

Okay, so. We'll start again and, probably improved anyway. 

#### monologue resumes

So. This article represents an experiment in open notebook knowledge where we create it, and make it available to the world.

At the time of, creation. Now, there are no easy tools for that at the moment.

There are some tools which do parts of it. But no tools which do the whole of it.

So this is very ambitious. And it means that the result of this is going to be a snapshot of what we do.

And also parts of it are going to be more developed than other parts so some of the parts will be examples rather than complete production.

#### internships

The way we work is important. We work by having internships at NIPTR.

And volunteers who support that. When they're able to find time. For that. And it means we have a particular style of development.

It's got a cycle to it so interns come in psychically perhaps twice a year but not always on the same starting date.

And they work for period between 2 and 6 months depending on the internship. There are no, paid authors in this.

But NIPGR, make staff available, for managing this. And we're very grateful to, Renu and to Gita or, efforts they put in.

The article is going to have an authorship from everybody who has contributed significantly over the period of about.

4 years. To this effort. And the authors. This recognizes the contribution of the authors.

It does not necessarily mean that individual authors adhere to everything that's said in this because at the contents here.

If printed out, would run too many hundreds of pages. It would be, at least a large book.

I'm, the I'm the main coherent backbone to authorship.

So, any concerns about, so any concerns about authorship should come to me. And not to other authors.

We are very restricted by the lack of tools for this elsewhere in this we have talked about the tools that we use for software.

They are very well developed and they are universally used in the world community. I contrast, and there are relatively few tools for authoring.

Documents in this type of setting. There are some, communal authoring tools, but they are not generally semantic.

So. We are moving into new territory. And we generally convert legacy material to semantics rather than author it directly.

In semantic form. And we have huge friction in the system. Which means that we move much slower.

Than we would do if there were, modern tools for semantic documents. Friction is where you have to have humans making some of the operations.

And, they include things like, downloading files, clicking on links.

Editing parts of documents and so forth and so on. And scholarly publication is set up.

On the model at each document. Requires individual attention. So even with repositories. We have to manually download documents from them.

And that's reason and that's why we wrote pi get papers why i wrote i get papers and because it's a major advance in terms of and automating at the process of large scale literature view.

That's a background. The components of our system. This overview. A table of contents navigation Hey, section on philosophy and.

This deals with Why we're doing what we're doing. What the, 6 successes of.

Open access are and what it's limitations. It deals with what we think SRR would have wanted to do in 2,024 100 years on from.

His birth. And. Some recommendations.

As to how the current system could be checked.

#### tools and interns
We then talk about methods of development. How we create. The material. And that we're using.

And this deals with the, internships. Familiarity with the tools.

The way that new interns are brought in. And get up to speed with the technology that we've got and how the.

Emphasis is on, communal help rather than individual competition. Which is so common in academia.

After the interns, come up to speed with the tools. There then have well-defined tasks.

### corpora
And those tasks are, based on a corpus that we are dealing with. We have 3 corpora approximately.

#### IPCC Reports

We have the IPCC. Reports. We have the IPCC.

#### UNFCCC COP reports

And we have the UN FCC cop reports we also deal with,


#### pygetpapers

We also deal with reviewing the literature. Using pygetpapers.

#### docanalysis

And docanalysis. And to make this easy, what we do is parallelize it so that every intern as a subject.


* At the moment they pick a chapter in IPCC reports, one that they are interested in and can work with.


* They convert it to HTML form. Although I hope that most of that's already been done.


* They, Get a feeling for what's in it. And then, they analyze it using docanalysis and Amy tools to find out what words are in it and to index and to.

* Using. They also, choose a number of entries in the IPCC glossary.

Initially by taking an initial letter that nobody's taken before. And they enhance there's,

Enhance those. Across 3 items, using, Wiki data, and Wiki, other Wikimedia.

Approaches. So hopefully most of the glossary items link to, Wikipedia entry which is relevant.

That then links to a wiki data item on that. And the wiki data item also gives things like additional reading.

So that you can put in A few high level. Articles which would back up. What's in the material.

So, That model means that it scales when somebody new comes in. They've got a clear task line.

Get up to speed with the technology, choose a chapter, choose a and then, make your chapter as semantic as possible.

Make your glossary entries as semantic. As possible and ontologically enhanced with Wikipedia and Wikipedia.

And then, If there is time, carry out a literature review on your subject using, I get paper stock analysis.

And making that literature report available to the world and probably limited in limiting it to the last

You know, let's say the last 50 or a hundred papers by putting a date rate.

Date range in.

So, that's the, management of the and internships. Now.

#### Anmol project

[Anmol Negi] 09:45:54
I want to say something. Yeah, so I have my own, 3 publications in the coming semantic communications.

Sure

[Anmol Negi] 09:46:04
So, one of it says, about plastic. As you said, as an intern, we have to like search, some, glossaries in the IPCC.

Yes.

[Anmol Negi] 09:46:18
And do then the, Python, all the tools we have to use in it. So I want to say that, I'm already doing such things in my, the upcoming publications and it's almost, I've almost, completed it like it's ready to, mmm, for, the, ising, which is the end, it is 20, th I guess.

[Anmol Negi] 09:46:43
right.

So, This is a general approach. And, what, we do and we work this out with Renu, who's still here, is that each in turn, does something which, makes sense.

Within their own background what they've already done and so on. So if you already have material on That's Very, very valuable and it may well be that what you should do is, try and find where in the whole of and IPCC plastics are mentioned.

I mean, I've no idea it's 25,000 words. And, I'm sure they mention it somewhere.

But it would be generally the interaction of plastics with climate. So do plastics affect the climate?

Or do climate affect the plastic and pollution problem. But then you will also be able to, search the latest literature using py get papers and annotating this with the dictionaries that we already have.

So, the subjects. That you might look for is plastic pollution and climate change, which allows you to annotate the, the climate change aspect of the articles and and you may also wish to make your own glossary dictionary on plastics.

Which could be done by extracting word clouds from the recent papers. Looking up those, word clouds, words in Wiki data, which will give you a semantic dictionary.

And then using that to index the papers for plastics does that make sense and more

[Anmol Negi] 09:48:59
Yeah. Yes, Peter. Got it.

Brilliant, brilliant. So, and that's a fantastic little snippet, which we will, highlight for the world because that's how we will, highlight for the world because that's how we work and it shows how we Oh, always.

Well, always changing our goals because, This move so fast and our technology is able to do things it wasn't able to do last year.

So that's brilliant.

#### more management

Okay, so. Back to, how we manage this. We managed this from the top down by, individuals having individual projects as you just heard.

And then we have, a number of tools, which support this. So the primary tool is meeting every.

Day on zoom. And discussing and recording this. Now, In the past we've had in turns where after a initial period it hasn't been necessary to do zoom every day.

I think here, Reno, we've had a situation where new people have come in.

So it's been necessary to do Zoom sessions every day for the newcomers. And of course we have this deadline.

Of 2 days time where we are. Producing material for that but after that for the you know, the,

What? I call it the. Earlier join us. It's not necessary, to do 2 h every day.

[Renu Kumari] 09:50:53
Hmm.

And we've certainly found in the past that a much less frequent is necessary.

[Renu Kumari] 09:51:05
For that we need to give them the title of the work and the how they are going to work because sometimes they don't know how to scrap the test and how to get the like a tutorial, and things like how they are going to dictionary because, till now they are not able to understand the glossary from the IPCC or the glossary from the glossary from the IPCC or the glossary

[Renu Kumari] 09:51:28
from the So maybe I'll have to take a Zoom session to individually eat them because it's today's busy for you so I'll have to do that.

Yeah, that's tremendous for a new. That makes a lot of sense. And, You know, these are not.

Boring lectures to sit through. This is a mixture of Newcomers who need this amount of material.

[Renu Kumari] 09:51:56
Hmm. Yes.

And also, you are helping a great deal in organizing our communal thoughts. So that having these recordings is an incredibly valuable way of capturing our general thinking.

[Renu Kumari] 09:52:14
Hmm. Hmm. Oh, I'm leaving now. You can continue all back.

Yeah. That's tremendous. Okay, so we have Zoom. And, the Zoom is actually a, it's a, paid for zoom which I get on my Cambridge University accounts.

[Renu Kumari] 09:52:18
I'll be back in a half an hour.

### recording systems

#### Zoom

And zoom has been continually developing useful tools so what it has is Hey, video recording with an audio stream.

An audio stream which I think is the same as in the video but that has the advantage of being smaller and therefore we can post it to get.

And easier. The audio stream is about 50 MB the video stream can be up to 500 or more megabytes.

And then, Zoom automatically does transcription. It took us a while to learn that We could do this, but if we switch on the transcripts.

It produces a very use usable English language transcript. Of the session. With the main drawback that it is.

Unfortunately he trained for English speakers so it does better on my contributions than some others and it also doesn't know the Indian name so the Indian names are often garbled and we have to go through and edit those.

And either manually or with a reg X. So we have the transcript. which We then post into Slack.

#### Slack

Now, Slack is A fairly closed system. It's a social media system for collaborative work, but it is designed primarily for companies who can afford their own system.

So to have a full slack, which preserves everything forever. Requires something of the order of probably with our numbers $10,000 a year and we haven't got $10,000.

So we use the free slack system, which does a good job of allowing us to communicate.

Within a few weeks. Of, the event. It also has a transcript system, but I don't think that's, adds anything to what we've got.

From zoom. It doesn't seem to be as good. So.

What we do is we use that as a container for our material we paste. All of the Zoom components into it, the audio, the video.

The transcripts and we also discuss things on slack by text. We don't have voice.

Sessions on Slack. And that text is very useful in the short run. We have a number of channels.

And the main channels we have are `#coordination`. Which, is used by everybody and has about 200 members on it.

Many of them not active at the moment. A channel on Get papers for PI get papers, a channel on.

Amy, Channel on climate which does Amy climate and then some general slack tools like

Recent, world events and, random contributions. Is there anything I've missed that people find useful on, oh, where does any introduction channel as well?

Any other channels on Slack?

Okay, and then the 3rd thing we use, so we don't rely on Slack for the history.

We have to get everything into. The next thing I mentioned, GitHub. So GitHub, is, Hey, commercial tool run by Microsoft which allows posting of open material on the open web.

And it works very well apart from the fact that it is controlled by a closed Corporation and in principle, it could stop tomorrow.


#### github

Now if that happened, there would be a huge out. From the open source community and my guess is that they would probably copy everything from the current, GitHub and fork it.

So I'm reasonably, reasonably confident that won't happen in the near future. But it is always very, very dangerous to rely on.

And I. So GitHub. 10 band users and it's at the moment and one user But no reason that we know.

And ideally we want open systems that we can use. I'm not clear what the good open systems are for these various things and it takes a lot of friction we have to there's a lot of friction in moving So, we're not going to move any time soon.

But we will follow the forefront of the an open source. community.


# repositories 

For our, code. We use repositories. On GitHub.

I've mentioned the ones that we use. For Pythagoras, and, and so on.

So all our code, is there or the world to see and Yeah.

We then come on to narratives. We have. Narratives are a very good way of.

Saying what we want to say to the world and getting feedback from the world. Ideally, we would have daily conversations with the world.

But at the moment, we have very few members from outside. The, registered, community on slack and github hopefully that will change.

The main place where this has happened is I get papers which has been forked. Many times and on Pi Pi, forking is a Beneficial thing for software.

People take a copy of it. Develop their own approaches and they may at some stage they don't have to but they may contribute back.

To this But generally our presentations are 2 fold. We have presentations to the world.

And they consist of slides and videos. And these presentations often happen. Either at the end of an internship.

So at the last round of internships. We made some videos. Oh, the interns made videos.

Or when we've got a public presentation. So we've made many public presentations.

Probably the last one, that we did with a lot of components was or code data. Where a number of members made presentations and video form.

And those were made available. You know, to the world for the code data presentation.

The videos are sometimes company by slides so people have produced a slideshow which makes sense in its own right.

And perhaps without very much commentary. And the second type of narrative is what I'm doing at the moment.

These are mainly monologues by myself. And there to try to pull together the, components that we've got.

And, to have a coherent, narrative through them. So in academic terms these would be called lectures.

I don't think of them as lectures so much. But, they have a fixed period.

And they covered a relatively, well-defined set of content, although, and they're always open to, interjections from the rest of the community.

So we're making a number of these lectures available, on the, presentation.

Then we come to repositories. Now, we've got 2 main, the main things that go into repositories.

Code documents and presentations. We've really talked about, the code.

But the way repositories work And is that they are highly versioned. And we commit new versions.

At frequent intervals. So, often there are person a day and sometimes.

Several versions in the day sometimes. No, for several days. But the point is that every significant change in a piece of information is versions and can be referred to by a version number.

And this 1st number is, semantic. in other words, it tells you where to find this.

It's not always semantic. Okay, scrub that last bit.

So what we put in repositories are code and documents. And then we also put our videos in YouTube.

It's not so easy to see that as a repository.

Then, we have, Complex objects. And here I'm going to talk about figures.

So I'm going to show you The figures we have at the moment.

These are figures that I've created over the years. Here, for example.

Is a table. As to what the JavaScript, let me see if that gets bigger it does.

Okay, so this is the Java based version of. Amy, this is probably, 10 years old.

And, represents a still very much the strategy we've got at the moment. So down here is.

A list of the papers from PYGET papers. And across here are the various components we've looked for.

In the paper and then here are the various things and they are linked to Wikipedia or Wiki data.

So this is a completely semantic table. Which we will be moving to more semantic things.

And in the future. I'm not going to go through all the Articles, but.

What I have created here. Is the table of the figures.

Oh, it's actually up here because So this is. A

Okay, table of all the figures, that I've accumulated over the years which relate to the processes, that we do here.

And I'm going to include a number of these in the article. Now, some of these because will create it 10 years ago, but they all represent the basic.

Semantics of what we do at the moment. I'm not going to go through all of them at the moment.

But let's have a look at a few of them.

This is an overview of how we make semantic. And objects here We can come with a text or HTML or images.

And create a whole number of semantic objects. Which are down here. Like species. And compounds and identifiers.

And these will be turned into data objects. So all of this underlies the design of our current.

Amy Tools at the moment.

Here's an example of, get papers. And a companion tool called quick scrape which Hi, a list of, URLs.

And takes the various components here. Put some into a tool chain. And then, and. Ultimately ends up with hey, semantic object.

I'm not, as I say, I'm not going to go through all of these. At the moment I've probably mentioned this one.

No, I Mentioned this one. Which is.

Complete workflow for. The discovery and cementification of, open articles. And here's get papers at the end and what it queries.

The various types of documents it deals with. Norma is an early version of Amy. And we make taggers.

We look at the structure of the document and ultimately we come up with visualizations and analysis. So that's our workflow.

It's somewhat different at the moment in detail, but in overall, scheme. It's the same as it was 10 years ago.

And there are a number of. Pictures here some of them political does anyone know who did these pictures?

I think it was later that. Huh. We'll ask her to comment on that.

So these figures will go into the word document. And we will put a lot of them in the Word document.

So that there would be a good, When I've talked about PDF, I also mean Word, so they'll go into the Word document.

And we will make a nice a narrative that.

So the final thing I want to say, perhaps could have come earlier. Is about history

And. The. A little bit about. The whole history of, semantic climate.

Now.

We started working on climate 4 years ago. But,

Some of us started working on semantics. 20 years ago, well, probably 30 years ago, based on the semantic.

So the history can be a bit useful here because the codes and the design that we use, were actually designed.

Probably 15 or 20 years ago and really haven't changed very much. The.

Somantics were developed. In my group in Cambridge over the period let's say 2,004 to about 2,011.

And it culminated. In a.

Meeting. A sort of fest. Griff in 2,000 and. 11 called visions of a semantic molecular future.

And that's when, we laid down a lot of the semantic principles, that we're still using today.

Because there has been Very little semantic progress. In this area over the last 10 to 13 years.

Then, it means that the ideas there are, still valuable for what we're doing.

One thing I will mention is that this was based on a chemical movement or community called the Blue Obelisk.

And the blue obelisk was a large number of,

Okay.

Put it in here.

No, that's not.

We'll go back to this one.

Well, if I can find it.

Well, let's go back to, yeah, here we are.

And the blue obelisk here. Was started about 20 years ago and it was a movement. And it had no funding.

And, it worked, by mutual co-OP cooperation, and the award of little blue obelisks.

I will show you a blue obelisk.

So here, can you see the blue obelisk?

It's made out of agate. It's very attractive. And they're not expensive, you know, you can.

If you know where to look, you can get them for about $10. So every year, Let's honor these people because they have.

So. Yes, and. Yeah, The, codes and the systems.

Which people have developed which all interact operate together and probably the key semantic tool here is chemistry development kit.

Which holds much of the software which can manage this. And chemical markup language. Which Henry Zaprana developed.

Which is the semantics of, of chemistry. And,

What we did is hand out Prizes to people. So here are some of the people. Who got prices?

We run out of doing it a few years ago. But all these people have made major contributions.

So what we do

As we pick up on this social idea. And we have Hey, and so people who help with the development here, semantic climate.

You know, if we can do it. We give them Amy's and A whole lot of Ames are being shipped to India for people who complete their internship and make a significant contribution.

To the project. You have to finish your internship and produce something. Which is valuable at the end of it.

So. So for things matter very much. It's something that academia has completely lost.

Academia has developed competition. Rather than collaboration by relying on, the, impact factor.

As the tool to measure somebody's worth. Yeah, we measure people's worth by how collaborative they are.

Okay, so. That's, the history of semantics. Now I'll say a little bit about, some of the As some of the changes we've had to make over these.

15 or 20 years. Everything changes. So the language is change. The tools change.

The outlook changes. So initially, we put our oh, initially we put our, codes in.

Some C CVS repository. I can't remember. What it is. We then move them to something called bitbucket.

And all the Java code was put in Bitpocket. Probably 20 or 30 different programs.

For chemistry and then bit bucket. Used a tool called mercurial and, and that started to get closed down so we then moved to GitHub.

Now every time you say move That is a massive amount of friction. So there's been a great deal of friction in keeping this all up to date.

The system for repositing has changed. So we started with I think just rural files. Then we had CVS.

Which was a version system. Very Centralized that moved to something called SVN. And then that moved to get.

No, then that moved to Mercurial. And then we had to move to get.

So all of these involves moving between one repository and another. And that can take months of work.

And it doesn't get recognized. None of the work I'm talking about here gets academic recognition.

And in fact it's 1 of the problems why the academic tools are or because they don't get.

Recognition and very often don't get support. And then in terms of languages, we have moved from.

At the beginning we started with and C plus plus, that was many years ago. Then move to Java.

And then in the last. 3 or 4 years. But we moved to Python. And without moving to Python, we would not have been able to have this community today.

So that's the history of some of the major movements. And that we have had. To make So that is the monologue.

It's going to need a lot of. Editing in places, but mainly just. Chopping out and so on and be particularly exciting to see if Hassel is able to summarize any of that.

Before we finish and that's finishing for the day. Are there any comments queries.

[smriti] 10:21:19
Peter, like I have, already made the list of the words, from the chapter, which I selected.

[smriti] 10:21:26
So where do I have to post that? Like I've written it in a word dog. So do I have to write the words individually or just?

That?

Okay. First, st little, Procedural thing is never use word documents for data, right?

Because words has all sorts of additional markup in. Which causes problems. What we just need is a simple text file.

Do you have a text editor?

[smriti] 10:22:05
Hmm.

Okay, well you can probably use. Bs code or, Hi, Charm for this, but you just need a file called dot TXT, right?

[smriti] 10:22:20
Yeah.

I mean, literally, you type it. So, take these words out, put them into a text.

That will make sure that I hope that you get rid of all the words stuff. And then that's all you need.

Now I have written a tool somewhere in Amy Lib. Which is able to look up all the words in wiki P.

And if we can do that, it'll look up. the words in Wikipedia as well.

So all you need is a word list. Does that make sense?

[smriti] 10:23:02
Yeah, Peter.

No, it will need to wait until after we've submitted this manuscript because at the moment that's the only thing on my mind.

But, that should be fine. And how many words have you got roughly?

[smriti] 10:23:26
Just a second. I just see.

You can leave your microphone on.

Okay. Has anybody else started compiling word lists?

[Anmol Negi] 10:24:00
I'm just a step back from this.

Right, okay. So, The point about this is that the word list is going to deal with Words which you think it's valuable for the world.

To have made semantic. So. Let me take a piece of.

Text here somewhere or other.

[smriti] 10:24:30
Weater it's roughly 65 words.

That's a very good number and how many of them do you think are specific to your chapter or high frequency in your chapter and not in others and how much of them a general climate words.

[smriti] 10:24:48
You know, I think it's 50% general for my chapter

That's That's wonderful. Okay, so what we will, do is we'll make your, We'll make your dictionary semantic.

It will actually, we used to do this in XML, but I actually think it's now better to do it in HTML.

And then we will, Find out whether other people have got the same words as you.

Right? And if Let's say, so what is your chapter?

[smriti] 10:25:31
Wg one chapter 3 human influence on the climate.

Okay, and, what's your chapter?

[Anmol Negi] 10:25:40
WG 3 climate change food security.

Right. Okay. So There are fairly different aren't they? So we can expect a food security thing is going to have things about.

Bloods and pests and diseases and a viable temperature for crops and things of that sort.

[Anmol Negi] 10:26:05
Yeah, I'm basically focusing on the like in the meet industries.

Fine. Okay, yeah, that's that's perfectly okay. So, well, then you will have things like cattle, and, night for socks.

[Anmol Negi] 10:26:11
Like some.

Now, well, you'll have cattle, and you will have, grazing deforestation.

[Anmol Negi] 10:26:32
Thanks, and.

Also, exactly. Yes, absolutely. And then, you will have things which, will also have.

[Anmol Negi] 10:26:37
Mike, microwave things and like that.

So you'll probably have in nitrous oxide, you'll probably have in.

You might have in things like, The auto protocol you might have in things. You know which

You know, Paris agreement, things of that sort. So You take your diction, right, in HTML and we'll work on that.

And then take, and we will overlap them. Now this is the, logical, a term called intersection.

Right. How much do they overlap? And, those. Might very well be common terms, so terms which other people will use and so on.

And then you'll have the things which are, unique to you, which will be meet and unique, which will be effect on climate and so on.

So, Whether we make one huge glossary, or whether we, make lots of small glossaries and some common glossaries.

Who knows? But this is really very, very exciting. And this will be probably.

The 1st thing that we can reasonably show to the world as being of great value. So in other words, if we can come up with a communal glossary here which is Growing.

And which we can say to the world, okay, we have arrived, we are creating this.

Oh, sorry. It grows every day. And so on. Then I think we'll find people who are interested in it.

So I think that if we can aim for that. You know, and we won't have completed it by the time any of the current interns finished.

But we will have enough of it to see if the rest of the world is interested in it.

Brilliant.

Any other comments questions?

[Anmol Negi] 10:29:05
I'm having a full week hackathon in the 1st week of 1st or second week of July.

[Anmol Negi] 10:29:12
So I won't be able to join.

Excellent. Okay, what's the hackers on on?

[Anmol Negi] 10:29:18
It's basically on the, based on, data science, we have to make some yeah, maybe out of the data set, it's been.

Right, and these data sets are, are they related to meat?

[Anmol Negi] 10:29:35
Not basically mate, but they have their own circumstances and conditions. So.

Yeah, that's fine. Okay, and what tools are you using? Do you know yet?

[Anmol Negi] 10:29:49
Yeah, basically, I think of, like basically, visualizations tools and some I'm thinking about using your tool as well.

Well, yeah. That would be absolutely brilliant. And, Presume, are you, are you doing any, the integration in Python?

[Anmol Negi] 10:30:07
Yeah.

[Anmol Negi] 10:30:20
Say.

Are you using Python as a basic? 2 language. Yep. Good.

[Anmol Negi] 10:30:24
Yeah, yeah, yeah.

Well, that's fantastic. You know, and come back to us and tell us how it went.

[Anmol Negi] 10:30:37
Yes.

Well, you'll be with us for a week or 2 yet, right. Okay. And is, is this in MRI,

[Anmol Negi] 10:30:42
No, it's in Dharadone. It's in India. Yeah.

Right, okay, this is great and who's organizing it?

[Anmol Negi] 10:30:54
There's, Dave, umi College. There's a college named, No, that.

Right, fantastic. This is exciting. Okay. So.

Okay, so.

I find it very difficult on Zoom to remember where people came from. So please, excuse me for, zoom to remember where people came from.

So please, excuse me for, not remembering everybody's, geographical locations and so on.

Okay, any other comments at this stage?

[Sravya] 10:31:41
We don't know what we collect from our chapter. We have to, I mean, run it and I believe, right?

Yes, but we'll show you how to do it and it takes about well, it takes.

A few seconds CPU, but it takes a bit longer to do the downloading. So probably takes, 2 or 3 min, but it's automatic.

[Sravya] 10:32:09
Yeah. So the goods we should. Right. The code.

All, all you do at this stage is find the words that either you don't understand or you think other people might not understand.

Or you think it would be really valuable to have, a Wikimedia backup to them.

So, human influence on climate, doubtless you will have. Greenhouse gas in there okay

Right? Do you have greenhouse gas as a phrase?

Hello?

[Parijat Bhadra] 10:33:05
I think we'll have that. The greenhouse gases like.

Yeah, okay. Right, so what you do with greenhouse gases, you want to make it as easy as possible.

For somebody that you've never met and never will met. To understand what a greenhouse gas is, right?

So, in that case, it's valuable if you have the abbreviation. So GHG because, if somebody gets a paragraph with GHG and it's less easy than greenhouse gas.

But what you, you know, what somebody will want to know is What does abbreviation mean?

What is a greenhouse gas? What are the greenhouse gases? No, list of the common ones.

Where can I find more information? That's what people want, right? Now, we can do all of that automatically using our tools.

[Parijat Bhadra] 10:34:02
Yes.

To a 1st approximation. Now, sometimes, you know, it'll get it wrong.

So, you know, if we looked for, something I'm going to pick one I know.

If you pick something like and T Rex, it will give you a pop group as well as a Hi, and you have to make the, decision as to which one should be in a climate lottery.

Probably neither. But you see the point. And so. There will be a certain amount of disambiguation.

Ideally we'd like to automate that and we probably can in the future but this is the 1st pass of what we're doing.

So. So just get those terms. All you have to do is get the terms.

And they're abbreviations if, and then we will do all the rest but we probably won't do that and we won't do that till Friday okay

[Parijat Bhadra] 10:35:25
Yes, Peter.

Right. Any more questions?

Okay, I am going to know

